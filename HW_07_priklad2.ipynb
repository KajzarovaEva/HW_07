{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATxlcgFXV8S3"
   },
   "source": [
    "# ChatGPT API\n",
    "\n",
    "Adapted from https://github.com/simecek/mlprague2024/blob/main/04_ChatGPT_API.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IrDz7Ru8yzIf"
   },
   "outputs": [],
   "source": [
    "api_key = \"\" ## You must change this to actual API key distributed during"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Or-fIghTy2iR",
    "outputId": "81bb78de-9b65-4753-d021-c77cdca4200d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Timestamp', 'Question:', 'Option A', 'Option B', 'Option C', 'Option D', 'Correct answer'],\n",
       "    num_rows: 90\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "dataset = load_dataset('kotlarska2/ABCD', split='train')\n",
    "#dataset = pd.read_csv('ABCD.csv')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRgk42A3Tn7i",
    "outputId": "eb751524-9714-4381-e06b-7a35fd465d71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Timestamp': '11/11/2024 11:18:42',\n",
       " 'Question:': 'Jaký máme rok?',\n",
       " 'Option A': '1876',\n",
       " 'Option B': '2014',\n",
       " 'Option C': '2023',\n",
       " 'Option D': '2024',\n",
       " 'Correct answer': 'D'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IglYyBTYy--Y",
    "outputId": "b72fd8a2-a430-4df1-c8c0-613ba5f710c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which option A/B/C/D is the best answer for the question. Answer with one letter, no explanation.\n",
      "\n",
      "Question (in Czech): Jaký máme rok?\n",
      "\n",
      "Options:\n",
      "A) 1876\n",
      "B) 2014\n",
      "C) 2023\n",
      "D) 2024\n",
      "\n",
      "Answer (just 1 letter, A/B/C/D):\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(x):\n",
    "    question, options = x['Question:'], (x['Option A'], x['Option B'], x['Option C'], x['Option D'])\n",
    "    text = f\"\"\"Which option A/B/C/D is the best answer for the question. Answer with one letter, no explanation.\n",
    "\n",
    "Question (in Czech): {question}\n",
    "\n",
    "Options:\n",
    "A) {options[0]}\n",
    "B) {options[1]}\n",
    "C) {options[2]}\n",
    "D) {options[3]}\n",
    "\n",
    "Answer (just 1 letter, A/B/C/D):\"\"\"\n",
    "    return text\n",
    "\n",
    "prompts = [get_prompt(x) for x in dataset]\n",
    "\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RWNvyNN31TaE"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a92c5c76344bd0bd340d03aef1f8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"Arrr, me hearty! I be a swashbucklin' pirate chatbot, here to serve ye with me knowledge and me wit! Me name be Captain Chatbeard, the scourge o' the seven seas... o' conversation, that is! I'll be answerin' yer questions, tellin' ye tales o' adventure, and maybe even teachin' ye a thing or two about the pirate life, savvy?\"}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "def get_answer(prompt):\n",
    "    # Creating a message structure similar to the chat format\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Generate response\n",
    "    outputs = pipeline(\n",
    "        messages,  # Extracting the text content for input\n",
    "        max_new_tokens=3\n",
    "    )\n",
    "\n",
    "    # Return the first character of the response, converted to uppercase\n",
    "    return outputs[0][\"generated_text\"][2]['content']\n",
    "\n",
    "# Example usage\n",
    "result = get_answer(prompts[40])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "828b2460d6224e05a20c61f609a28e63",
      "0e476df68fc34e84b8203946ffe53dbd",
      "71f23228a9714066991d63efcf9ebf57",
      "ae7d1898459342828bda1d477e41762d",
      "1d16f75935ea4c219e7f55c85a8e244d",
      "c37200a1d2474853aae9fc31fd247291",
      "7016a5c13f9247d2a5817daecf291033",
      "aa0cdbfce13c490494fd097f6bb09341",
      "0a7328175015404382d2bc4eddf474da",
      "132ebc069c774ee8aed2891834c4baa3",
      "cb6d03feefae44c8b1543ff5fbbb1f9d"
     ]
    },
    "id": "DThee-xlzhER",
    "outputId": "1ee2da97-fd58-45d5-aa29-663d45e2dd79"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ca2cf0ce224b2c9d5cff90e91bc780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "answers = []\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "  a = get_answer(prompt)\n",
    "  answers.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TL5w0IrM0GZC",
    "outputId": "72b60e31-1ebc-41bf-e6e7-630a388f4b52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for answer, solution in zip(answers, dataset['Correct answer']):\n",
    "  if answer == solution:\n",
    "    correct += 1\n",
    "\n",
    "# 80% for GPT3.5 (11 mistakes)\n",
    "# 94% for GPT4 (3 mistakes)\n",
    "correct / len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yfrgMLS7QCR",
    "outputId": "c4197dfb-fb9b-4692-91ce-de3058858dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A {'Timestamp': '11/11/2024 11:19:23', 'Question:': 'Kdo jako první vyřešil Basilejský problém?', 'Option A': 'Jacob Bernoulli', 'Option B': 'Leonard Euler', 'Option C': 'Karl Weierstrass', 'Option D': ' Joseph-Louis Lagrange', 'Correct answer': 'B'}\n",
      "B {'Timestamp': '11/11/2024 11:20:37', 'Question:': 'Kolika let se dožil Bedřich Smetana?', 'Option A': '60', 'Option B': '84', 'Option C': '69', 'Option D': '47', 'Correct answer': 'A'}\n",
      "A {'Timestamp': '11/11/2024 11:24:13', 'Question:': 'Kto vyhral zlatú loptu v roku 2020?', 'Option A': 'Robert Lewandowski', 'Option B': 'Lionel Messi', 'Option C': 'Kylian Mbappe', 'Option D': 'Nikto', 'Correct answer': 'D'}\n",
      "B {'Timestamp': None, 'Question:': 'Kolik je jedna a jedna?', 'Option A': 'Osm', 'Option B': 'Jedna', 'Option C': 'Dva', 'Option D': 'Nula', 'Correct answer': 'C'}\n",
      "A {'Timestamp': None, 'Question:': 'Jaké je nejvyšší dvouciferné prvočíslo?', 'Option A': '11', 'Option B': '2', 'Option C': '97', 'Option D': '37', 'Correct answer': 'C'}\n",
      "D {'Timestamp': None, 'Question:': 'Ako pokračuje riekanka, ktorá sa začína slovami \"Aka fuka\"?', 'Option A': 'lunda muka', 'Option B': 'funda luka', 'Option C': 'kuka puka', 'Option D': 'nuka huka', 'Correct answer': 'B'}\n",
      "A {'Timestamp': None, 'Question:': 'Keď máme desať jabĺčok a dve zjeme, štyri zahodíme, dve kúpime a jedno stratíme. Potom kúpime aj jednu mrkvu. Koľko mrkiev máme?', 'Option A': '5', 'Option B': '1', 'Option C': '4', 'Option D': '6', 'Correct answer': 'B'}\n",
      "C {'Timestamp': None, 'Question:': 'Co se stane s vránou pokud liška běží k táboru?', 'Option A': 'Nic', 'Option B': 'Bude hladovět', 'Option C': 'Poletí za liškou', 'Option D': 'Zakráká', 'Correct answer': 'A'}\n",
      "C {'Timestamp': None, 'Question:': 'Aká rieka tečie cez hlavné mesto Slovenska?', 'Option A': 'Orava', 'Option B': 'Dunaj', 'Option C': 'Váh', 'Option D': 'Nitra', 'Correct answer': 'B'}\n",
      "C {'Timestamp': None, 'Question:': 'Koľko nôh má kôň?', 'Option A': '1', 'Option B': '8', 'Option C': '3', 'Option D': '4', 'Correct answer': 'D'}\n",
      "B {'Timestamp': None, 'Question:': 'Mám tři jablka, ze dvou udělám štrůdl a jedno další koupím. Kolik budu mít jablek?', 'Option A': 'pět', 'Option B': 'čtyři', 'Option C': 'jedno', 'Option D': 'dvě', 'Correct answer': 'D'}\n",
      "A {'Timestamp': None, 'Question:': 'Koľko trojciferných čísel vieme vytvoriť z číslic 1,2,3,4 pričom číslice sa nemôžu opakovať?', 'Option A': '4', 'Option B': '12', 'Option C': '24', 'Option D': '64', 'Correct answer': 'D'}\n",
      "A {'Timestamp': None, 'Question:': 'V ktorom meste sa narodil Stephen Hawking?', 'Option A': 'Londýn', 'Option B': 'Oxford', 'Option C': 'Brighton', 'Option D': 'Edinburgh', 'Correct answer': 'B'}\n",
      "D {'Timestamp': None, 'Question:': 'Aká je hodnota X pre rovnicu X=3×(2+2)', 'Option A': '4', 'Option B': '6', 'Option C': '12', 'Option D': '9', 'Correct answer': 'C'}\n",
      "C {'Timestamp': None, 'Question:': 'Proč je obloha modrá?', 'Option A': 'Obloha modrá není', 'Option B': 'Obloha je modrá díky vysokému obsahu dusíku v atmosféře', 'Option C': 'Obloha je modrá, kvůli toho v jakém spektru vyzařuje Slunce', 'Option D': 'Nesmyslná otázka', 'Correct answer': 'B'}\n",
      "C {'Timestamp': None, 'Question:': 'Ktorá z uvedených zelenín je oranžovej farby ?', 'Option A': 'Paradajka', 'Option B': 'Mrkva', 'Option C': 'Paprika ', 'Option D': 'Cibuľa', 'Correct answer': 'B'}\n",
      "C {'Timestamp': None, 'Question:': 'Ako dopadol Korčok v posledných voľbách', 'Option A': 'Nie dobre. Prehral.', 'Option B': 'Korčok prehral s rozdielom niekoľko tisíc hlasov v posledných preziedentských voľbách na Slovensku.', 'Option C': 'Korčol bol kandidátom v posledných prezidentských voľbách na Slovensku. V týchto voľbách bol výťazom.', 'Option D': 'Korčok je ryba slanej chuti. Korčok žije v mielčinách severného mora. Chutia mu chobotnice a ľudia.', 'Correct answer': 'B'}\n",
      "B {'Timestamp': None, 'Question:': 'Vypočítaj, koľko % je 5 z 50.', 'Option A': '9', 'Option B': '5', 'Option C': '10', 'Option D': '1', 'Correct answer': 'C'}\n",
      "D {'Timestamp': None, 'Question:': 'Koľko životov má podľa známeho príslovia mačka?', 'Option A': '4', 'Option B': '6', 'Option C': '9', 'Option D': '12', 'Correct answer': 'C'}\n",
      "B {'Timestamp': None, 'Question:': 'Jaká je přibližná genetická podobnost prasete s člověkem podle ChatGPT 3.5?', 'Option A': 'cca 35 %', 'Option B': 'cca 50 %', 'Option C': 'cca 90 %', 'Option D': 'Záleží na člověku...', 'Correct answer': 'C'}\n",
      "B {'Timestamp': None, 'Question:': 'Aký je mužský rod od slova letuška?', 'Option A': 'letušiak', 'Option B': 'letec', 'Option C': 'steward', 'Option D': 'stevard', 'Correct answer': 'D'}\n",
      "B {'Timestamp': None, 'Question:': 'Jaká stanice pražského metra leží na trasách A a B?', 'Option A': 'Můstek', 'Option B': 'Florenc', 'Option C': 'Kladno', 'Option D': 'Ječná', 'Correct answer': 'A'}\n",
      "A {'Timestamp': None, 'Question:': 'Co je to veselá kopa?', 'Option A': 'Šedesát vtipálků.', 'Option B': '60 šprímařů.', 'Option C': 'Pět tuctů klaunů.', 'Option D': 'Šprýmař, vtipálek.', 'Correct answer': 'D'}\n",
      "C {'Timestamp': None, 'Question:': 'Kdy zmrzne peklo?', 'Option A': 'Na začátku vesmíru', 'Option B': 'Na konci vesmíru', 'Option C': 'Při absolutní nule.', 'Option D': 'To se nestane.', 'Correct answer': 'D'}\n",
      "C {'Timestamp': None, 'Question:': 'Jaký je rozdíl mezi lamou a alpakou?', 'Option A': 'lama je menší než alpaka', 'Option B': 'alpaka je menší než lama', 'Option C': 'alpaka je větší než lama', 'Option D': 'lama není větší než alpaka', 'Correct answer': 'B'}\n",
      "A {'Timestamp': None, 'Question:': 'Čo je to fono v jazyku ulice?', 'Option A': 'telefón', 'Option B': 'fotoaparát', 'Option C': 'nástroj na fajčenie', 'Option D': 'kamarát', 'Correct answer': 'C'}\n"
     ]
    }
   ],
   "source": [
    "# List the mistakes\n",
    "\n",
    "for answer, x in zip(answers, dataset):\n",
    "  if answer != x['Correct answer']:\n",
    "    print(answer, str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brM50gEIVhNo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIdb35xNh0jpsyijfMsEJU",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a7328175015404382d2bc4eddf474da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e476df68fc34e84b8203946ffe53dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c37200a1d2474853aae9fc31fd247291",
      "placeholder": "​",
      "style": "IPY_MODEL_7016a5c13f9247d2a5817daecf291033",
      "value": "100%"
     }
    },
    "132ebc069c774ee8aed2891834c4baa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d16f75935ea4c219e7f55c85a8e244d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7016a5c13f9247d2a5817daecf291033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71f23228a9714066991d63efcf9ebf57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa0cdbfce13c490494fd097f6bb09341",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a7328175015404382d2bc4eddf474da",
      "value": 50
     }
    },
    "828b2460d6224e05a20c61f609a28e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e476df68fc34e84b8203946ffe53dbd",
       "IPY_MODEL_71f23228a9714066991d63efcf9ebf57",
       "IPY_MODEL_ae7d1898459342828bda1d477e41762d"
      ],
      "layout": "IPY_MODEL_1d16f75935ea4c219e7f55c85a8e244d"
     }
    },
    "aa0cdbfce13c490494fd097f6bb09341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae7d1898459342828bda1d477e41762d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_132ebc069c774ee8aed2891834c4baa3",
      "placeholder": "​",
      "style": "IPY_MODEL_cb6d03feefae44c8b1543ff5fbbb1f9d",
      "value": " 50/50 [00:24&lt;00:00,  2.05it/s]"
     }
    },
    "c37200a1d2474853aae9fc31fd247291": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb6d03feefae44c8b1543ff5fbbb1f9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
